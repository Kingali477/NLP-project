{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbaZQ8Xn9sx/xHH3d+66cS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kingali477/NLP-project/blob/main/sentimentanalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovgrW-7vweR0",
        "outputId": "35762945-57f2-4592-bc3b-46da4f2b7d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Package state_union is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download([\"names\",\n",
        "\"stopwords\",\n",
        "\"state_union\",\n",
        "\"twitter_samples\",\n",
        "\"movie_reviews\",\n",
        "\"averaged_perceptron_tagger\",\n",
        "\"vader_lexicon\",\n",
        "\"punkt\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "print(\"words = \",words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o821Xo-wyTT",
        "outputId": "4b96d11f-da87-4d47-f2fb-7583d1305b42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words =  ['PRESIDENT', 'HARRY', 'S', 'TRUMAN', 'S', 'ADDRESS', 'BEFORE', 'A', 'JOINT', 'SESSION']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "words = [w for w in words if w.lower() not in stopwords]\n",
        "pprint.pp(words[:20],width=88,compact = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5PktstDw2ma",
        "outputId": "e4049cb0-f667-46c7-eed8-b71c5496c79b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRESIDENT', 'HARRY', 'TRUMAN', 'ADDRESS', 'JOINT', 'SESSION', 'CONGRESS', 'April',\n",
            " 'Mr', 'Speaker', 'Mr', 'President', 'Members', 'Congress', 'heavy', 'heart', 'stand',\n",
            " 'friends', 'colleagues', 'Congress']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"For some quick analysis, creating a corpus could be overkill.\n",
        "If all you need is a word list,\n",
        "there are simpler ways to achieve that goal.\"\"\"\n",
        "pprint.pp(nltk.word_tokenize(text), width=79, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihtrzP3ww6Dt",
        "outputId": "0012ca95-5ad0-43ad-aab2-3cb206b069db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
            " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
            " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words: list[str] = nltk.word_tokenize(text)\n",
        "fd = nltk.FreqDist(words)"
      ],
      "metadata": {
        "id": "F8uDBbiww-WO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fd.most_common(10))\n",
        "fd.tabulate(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLSMFF4bxB1D",
        "outputId": "723de0a3-a28e-4109-bc7c-79e2f95739d2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 2), ('a', 2), ('.', 2), ('For', 1), ('some', 1), ('quick', 1), ('analysis', 1), ('creating', 1), ('corpus', 1), ('could', 1)]\n",
            "       ,        a        .      For     some    quick analysis creating   corpus    could \n",
            "       2        2        2        1        1        1        1        1        1        1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OI5Z2RAY5HNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_fd = nltk.FreqDist([w.lower() for w in fd])"
      ],
      "metadata": {
        "id": "DnfP90XLxJJQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(nltk.corpus.state_union.words())\n",
        "text.concordance(\"america\", lines=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2lJhGMfxMUy",
        "outputId": "44465a05-d672-4c83-b3f8-4fa70411d563"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 1079 matches:\n",
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n",
            "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
            " to make complete victory certain , America will never become a party to any pl\n",
            "nly in law and in justice . Here in America , we have labored long and hard to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concordance_list = text.concordance_list(\"america\", lines=2)\n",
        "for entry in concordance_list:\n",
        "  print(entry.line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVEqXJMixPKJ",
        "outputId": "579aa9e0-9c90-4bb0-eda3-a7b9cae33fc4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " would want us to do . That is what America will do . So much blood has already\n",
            "ay , the entire world is looking to America for enlightened leadership to peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1: list[str] = nltk.word_tokenize(\"\"\"Beautiful is better than ugly.\n",
        "Explicit is better than implicit.\n",
        "Simple is better than complex.\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "yv310n2uxTUF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
        "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
        ""
      ],
      "metadata": {
        "id": "TO5urheFxWN5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.most_common(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZimgaU9CxeED",
        "outputId": "1039f1cf-2040-41bf-e0cf-edafde4233dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('the', 'United', 'States'), 294),\n",
              " (('the', 'American', 'people'), 185),\n",
              " (('of', 'the', 'world'), 154)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finder.ngram_fd.tabulate(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj8B7nZ_xhqH",
        "outputId": "0a8ddddf-b8e9-483e-bb5b-11626b28a67a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ('the', 'United', 'States') ('the', 'American', 'people')        ('of', 'the', 'world') \n",
            "                          294                           185                           154 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sent = SentimentIntensityAnalyzer()\n",
        "result = sent.polarity_scores(\"Wow, NLTK is really powerful!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpVIo7Jkxk07",
        "outputId": "a2d1ace1-0e36-4704-f501-ee6f6ba73077"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
      ],
      "metadata": {
        "id": "t1jtcbDrxqQf"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "def is_positive(tweet: str) -> bool:\n",
        "  \"\"\"True is tweet has positive compound sentiment, False otherwise.\"\"\"\n",
        "  return sent.polarity_scores(tweet)[\"compound\"] > 0\n",
        "##############################################################################\n",
        "shuffle(tweets)\n",
        "for tweet in tweets[:10]:\n",
        "  print(is_positive(tweet),\"->\",tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKFtaEwQypcE",
        "outputId": "3cc55e25-627b-4862-a6dc-2c8e0833c764"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False -> \"@Nyesekkinn: Don't be affaraid, I'll Be there For You :)\"\n",
            "False -> I'm turning this Farage shite off and going to bed. #AskNigelFarage\n",
            "True -> @Zen_arcade_ @DDRFalke Probably not,will be a Tory led government of some kind.\n",
            "False -> I'm still secretly hoping a m/stream politician claims #SNP are so dangerous they should be banned. I want that shitstorm convo #BanTheSNP\n",
            "False -> SNP leader faces audience questions: Nicola Sturgeon tells a live TV audience in Glasgow that the SNP would have 'big influence and b...\n",
            "True -> RT @PaulineinAlba: @UKLabour @scottishlabour @NicolaSturgeon Miliband would rather put tories in power than respect the democratic vote of …\n",
            "True -> HAHAHA!  BAILEY MAY :) SUCH A FAN BOY OF ARIANA GRANDE!!  #PBB737GOLD\n",
            "True -> RT @abstex: The FT is backing the Tories. On an unrelated note, here's a photo of FT leader writer Jonathan Ford (next to Boris) http//t.c…\n",
            "True -> RT @dmccafferty49: Miliband saying he would rather have a Tory Govt than a Labour Govt supported by a democratic party supported by people …\n",
            "False -> Mr Farage,all the hospitals I have to use regularly, would collapse without their immigrant employees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "all_review_ids = positive_review_ids + negative_review_ids\n",
        ""
      ],
      "metadata": {
        "id": "b6va3J5py40V"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "def is_positive(review_id: str) -> bool:\n",
        "  \"\"\"True if the average of all sentences compound scores is positive.\"\"\"\n",
        "  text = nltk.corpus.movie_reviews.raw(review_id)\n",
        "  scores = [\n",
        "      sent.polarity_scores(sentences)[\"compound\"]\n",
        "      for sentences in nltk.sent_tokenize(text)\n",
        "  ]\n",
        "  return mean(scores) > 0"
      ],
      "metadata": {
        "id": "Oqu0aKn2y80C"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "shuffle(all_review_ids)\n",
        "correct = 0\n",
        "for review_id in all_review_ids:\n",
        "  if is_positive(review_id):\n",
        "    if review_id in positive_review_ids:\n",
        "      correct += 1\n",
        "  else:\n",
        "    if review_id in negative_review_ids:\n",
        "      correct += 1\n",
        "print(F\"{correct / len(all_review_ids):.2%} correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XWBxcfHy-5w",
        "outputId": "d2833c45-4519-4201-a1ae-87ff2203aaf6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.00% correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
        "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
        "#################################################################\n",
        "def skip_unwanted(pos_tuple):\n",
        "  word, tag = pos_tuple\n",
        "  if not word.isalpha() or word in unwanted:\n",
        "    return False\n",
        "  if tag.startswith(\"NN\"):\n",
        "    return False\n",
        "  return True\n",
        "###############################################################\n",
        "positive_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
        ")]\n",
        "negative_words = [word for word, tag in filter(\n",
        "    skip_unwanted,\n",
        "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
        ")]"
      ],
      "metadata": {
        "id": "T4bIMF3t0C9L"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_fd = nltk.FreqDist(positive_words)\n",
        "negative_fd = nltk.FreqDist(negative_words)\n",
        "common_set = set(positive_fd).intersection(negative_fd)\n",
        "for word in common_set:\n",
        "  del positive_fd[word]\n",
        "  del negative_fd[word]\n",
        "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
        "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
      ],
      "metadata": {
        "id": "7Yn38bwq102a"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#####################################################################\n",
        "stopwords = set(stopwords.words('english'))\n",
        "unwanted = stopwords.union(set(w.lower() for w in nltk.corpus.names.words()))\n",
        "####################################################################\n",
        "def is_valid_word(word):\n",
        "    return word.isalpha() and word.lower() not in unwanted\n",
        "###################################################################\n",
        "positive_words = [w for w in movie_reviews.words(categories=[\"pos\"]) if is_valid_word(w)]\n",
        "negative_words = [w for w in movie_reviews.words(categories=[\"neg\"]) if is_valid_word(w)]\n",
        "###################################################################\n",
        "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(positive_words)\n",
        "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(negative_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os-9RyLm1-HY",
        "outputId": "ea73d769-0f29-4f7c-b159-5a1908fcf037"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import nltk\n",
        "from statistics import mean\n",
        "\n",
        "def extract_features(text):\n",
        "    features = dict()\n",
        "    wordcount = 0\n",
        "    compound_scores = list()\n",
        "    positive_scores = list()\n",
        "    sent = nltk.sentiment.SentimentIntensityAnalyzer()\n",
        "\n",
        "    for sentence in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sentence):\n",
        "            if word.lower() in top_100_positive:  # Assuming top_100_positive is defined somewhere\n",
        "                wordcount += 1\n",
        "        compound_scores.append(sent.polarity_scores(sentence)[\"compound\"])\n",
        "        positive_scores.append(sent.polarity_scores(sentence)[\"pos\"])\n",
        "\n",
        "    if compound_scores:\n",
        "        features[\"mean_compound\"] = mean(compound_scores) + 1\n",
        "    else:\n",
        "        features[\"mean_compound\"] = 0  # Handle case when no scores are available\n",
        "\n",
        "    # Calculate mean positive score (assuming positive_scores is not empty)\n",
        "    if positive_scores:\n",
        "        features[\"mean_positive\"] = mean(positive_scores)\n",
        "    else:\n",
        "        features[\"mean_positive\"] = 0  # Handle case when no scores are available\n",
        "\n",
        "    features[\"wordcount\"] = wordcount\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "features = [\n",
        "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
        "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
        "]\n",
        "features.extend([\n",
        "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
        "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
        "])\n",
        "\n",
        "\n",
        "train_count = len(features) // 4\n",
        "shuffle(features)\n",
        "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
        "classifier.show_most_informative_features(10)\n",
        "print(\"#################################\")\n",
        "nltk.classify.accuracy(classifier, features[train_count:])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyCO4bil2CRE",
        "outputId": "4f1bdd6a-6f6d-416b-ef37-90e44830a99f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "               wordcount = 2                 pos : neg    =      3.9 : 1.0\n",
            "               wordcount = 4                 pos : neg    =      3.8 : 1.0\n",
            "               wordcount = 0                 neg : pos    =      1.6 : 1.0\n",
            "               wordcount = 1                 pos : neg    =      1.2 : 1.0\n",
            "           mean_positive = 0.09154545454545454    pos : neg    =      1.0 : 1.0\n",
            "#################################\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.668"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}